<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>The Story behind WGAN | rdh1115 Blog</title>
<meta name="keywords" content="Generative Models, Literature Review">
<meta name="description" content="An introduction to GAN and WGAN (code examples included).">
<meta name="author" content="Mark Bai">
<link rel="canonical" href="https://rdh1115.github.io/posts/literature/gan-wgan/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.fdc284e8bb37d457cb8ad90a4d6521985678fbc9839210c5c4e08ea1f6ea9c37.css" integrity="sha256-/cKE6Ls31FfLitkKTWUhmFZ4&#43;8mDkhDFxOCOofbqnDc=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://rdh1115.github.io/icons/brain_128.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://rdh1115.github.io/icons/brain_16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://rdh1115.github.io/icons/brain_32.png">
<link rel="apple-touch-icon" href="https://rdh1115.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://rdh1115.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://rdh1115.github.io/posts/literature/gan-wgan/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-KDGRSE9EJD"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-KDGRSE9EJD');
</script>



<script type="text/javascript" id="MathJax-script" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.0.0/es5/latest?tex-mml-chtml.js">
</script>
<script>
    MathJax = {
        tex: {
            inlineMath: [['$', '$'], ['\\(', '\\)']],
            tags: 'ams'
        }
    };
</script>
<script id="MathJax-script" async
        src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
</script>

      <script async src="https://www.googletagmanager.com/gtag/js?id=G-KDGRSE9EJD"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-KDGRSE9EJD');
        }
      </script><meta property="og:url" content="https://rdh1115.github.io/posts/literature/gan-wgan/">
  <meta property="og:site_name" content="rdh1115 Blog">
  <meta property="og:title" content="The Story behind WGAN">
  <meta property="og:description" content="An introduction to GAN and WGAN (code examples included).">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-21T00:00:00+00:00">
    <meta property="article:modified_time" content="2025-01-16T17:14:20-05:00">
    <meta property="article:tag" content="Generative Models">
    <meta property="article:tag" content="Literature Review">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="The Story behind WGAN">
<meta name="twitter:description" content="An introduction to GAN and WGAN (code examples included).">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://rdh1115.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Literature",
      "item": "https://rdh1115.github.io/posts/literature/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "The Story behind WGAN",
      "item": "https://rdh1115.github.io/posts/literature/gan-wgan/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "The Story behind WGAN",
  "name": "The Story behind WGAN",
  "description": "An introduction to GAN and WGAN (code examples included).",
  "keywords": [
    "Generative Models", "Literature Review"
  ],
  "articleBody": "This post explores the theory and some follow-up papers of one of the most influential machine learning papers: Generative Adversarial Networks (GANs). Contrary to other deep learning models, I find that generative models are supported by more rigorous mathematics that are easily digestible.\nAs we understand the theory behind GANs (mostly through the paper by Arjovsky and Bottou, 2017), we will recognize its limitations and the reason behind its instability. This naturally leads us to Wasserstein Generative Adversarial Networks (WGANs), which apply useful concepts from Optimal Transport (OT).\nSince these papers are quite “old” by machine learning standards, there are many blog posts that already discuss them. The following is my own understanding plus some parts I find missing in other posts. A Kaggle notebook is also provided to compare the algorithms learning on a toy example: Kaggle Notebook Link\nGANs Cool History The story is that GAN was conceived at a bar in Montréal (Les 3 Brasseurs) by Ian Goodfellow during his Ph.D. studies. At the bar, he proposed GAN to his friends, but quickly faced skepticism.\nThe idea of jointly training a pair of networks against each other seemed too difficult when training just one network was difficult enough. Perhaps due to the influence of alcohol, he was still confident, so he headed home, coded up GAN, and produced amazing results on MNIST (a handwritten digit recognition dataset).\nAs of today, the seminal paper published in NeurIPS has over 75,000 citations, and has become a cornerstone in the field of unsupervised learning.\nGAN Architecture (Goodfellow et al., 2014) GANs learn the latent distribution of the unlabeled data through a pair of networks (the generator and the discriminator) that are competing against each other. An analogy is used in the original paper: the generator is a team of counterfeiters that produces fake currency, while the discriminator is the police trying to detect forgery. When both networks are optimal, the generator is able to produce counterfeit currency that is indistinguishable from the real ones.\nFigure 1: A GAN consists of two components: the discriminator $D$ outputs the probability that a given sample is real, and the generator $G$ produces synthetic samples given a latent variable $z$ sampled from the base distribution, e.g. $z \\sim \\mathcal{N}(0,1)$. The discriminator parameters $\\theta_d$ are updated to assigns high probability to real samples and low probability to synthetic samples, while the generator parameters $\\theta_g$ are updated to \"fool\" the discriminator into assigning high probabilities to the synthetic samples. First, let’s define $p_z, p_g, p_r$ as the probability distributions of the latent variable $z$, the generator, and real samples respectively.\nThe discriminator $D(x,\\theta_d)\\to [0, 1]$ outputs a scalar that represents the probability that $x$ came from $p_r$ rather than $p_g$. The generator $G(z, \\theta_g)$ then learns a mapping from $z$ to the data space. In other words, it is learning $p_g$ over data $x$, where $x\\sim p_r(x)$.\n$D$ is trained in a binary classification fashion. It maximizes the probability of assigning the correct label to both real samples $x$ and fake samples $x’ = G(z)$. This is equivalent to maximizing $$\\max_D \\mathbb{E}_{x\\sim p_r(x)}\\left[\\log (D(x))\\right] +\\mathbb{E}_{z\\sim p_z(z)}\\left[\\log(1- D(G(z)))\\right].$$\nThe generator then minimizes the probability of the discriminator assigning the correct label to the fake samples: $$\\min_G \\mathbb{E}_{z\\sim p_z(z)}\\left[\\log(1- D(G(z)))\\right].$$ In other words, they are playing a MinMax game with the following loss function: $$ \\begin{equation}\\label{eq: gan_loss} \\min_{G}\\max_{D} L(G, D) = \\mathbb{E}_{x\\sim p_r(x)}\\left[\\log (D(x))\\right] + \\mathbb{E}_{z\\sim p_z(z)}\\left[\\log(1- D(G(z)))\\right] \\end{equation} $$\nHow to train GANs Since the discriminator and the generator are playing a two-player non-cooperative game, training them can be difficult, and similar to finding the Nash equilibrium (Salimans et al., 2016).\nIn practice, this is traditionally done with the following pipeline: in each training loop, fix the generator and update the discriminator for $k$ steps, then fix the discriminator and update the generator for 1 step.\nTo update the discriminator, we fix the generator and isolate the $\\max_{D} L(G, D)$ part of Equation $\\eqref{eq: gan_loss}$: $$ \\begin{aligned} L(\\theta_d) \u0026 = \\mathbb{E}_{x\\sim p_r(x)}\\left[\\log (D(x, \\theta_d))\\right] + \\mathbb{E}_{z\\sim p_z(z)}\\left[\\log(1- D(G^*(z), \\theta_d))\\right] \\\\ \u0026 \\approx \\frac{1}{m}\\sum_{i=1}^m\\left[\\log (D(x_i, \\theta_d))\\right] + \\frac{1}{n}\\sum_{j=1}^n\\left[ \\log( 1 - D ( G^* (z_j), \\theta_d)) \\right], \\end{aligned} $$ where $m$ represents the number of real examples, $n$ represents the number of fake examples, and $G^*(z)$ represents the fixed generator.\nTo update the generator, we use the following loss function: $$ \\begin{aligned} L(\\theta_g) \u0026 = \\left(\\mathbb{E}_{x\\sim p_r(x)}\\left[\\log (D^*(x))\\right] + \\mathbb{E}_{z\\sim p_z(z)}\\left[\\log(1- D^*(G(z, \\theta_g)))\\right]\\right) \\\\ \u0026 \\approx \\frac{1}{n}\\sum_{j=1}^n\\left[ \\log ( 1 - D^* (G(z_j, \\theta_g)))\\right] \\end{aligned}. $$ Note that we remove the first term since it is not related to $G(z, \\theta_g)$.\nThe Optimal Discriminator and Generator It is intuitive that in theory, the perfect generator replicates the entire data space, in other words, $p_g = p_r$ (see proof below). It is natural then to think that the perfect discriminator can always differentiate between real and synthetic samples, however in theory, the best discriminator achieves random guessing.\nLil’Log provides a great breakdown on the math behind this. The general idea is that if we take the derivative of the discriminator’s loss function with a fixed generator, and set it to zero, $D^*(x) = \\frac{p_r(x)}{p_r(x)+p_g(x)}$. And since the perfect generator enables $p_g = p_r$, $D^*(x) = \\frac{1}{2}$.\nGiven $G^*(z, \\theta_g)$ such that $p_r = p_g$, and $D^*(x, \\theta_d)$ such that $D^*(x) = \\frac{1}{2}$, we can derive the global minimum of the loss function: $$ \\begin{aligned} L(G^*, D^*) \u0026= \\mathbb{E}_{x\\sim p_r(x)}\\left[-\\log2\\right] +\\mathbb{E}_{x\\sim p_g(x)}\\left[-\\log2\\right]\\\\ \u0026= -2\\log2 \\end{aligned} $$ Thus, the best possible value of $L(G, D)$ is $-2\\log2$.\nTangent on KL \u0026 JS Divergence Kullback-Leibler (KL) divergence is one of the most commonly used measures in machine learning for comparing two probability distributions. Given distributions $p, q$, it measures how different $q$ is from $p$ with the following formulation: $$ KL(p\\Vert q) = \\int_{x}p(x)\\log\\frac{p(x)}{q(x)}dx. $$ Usually, $p$ is the true distribution, and $q$ is the model. The interpretation from information theory is that KL divergence measure the extra information gain (relative entropy) when switching from $q$ to $p$.\nThere are many limitations to KL divergence, one of the most being its asymmetry. If we explore the Wikipedia page for KL divergence, we will find that the Jensen-Shannon (JS) divergence addresses this issue by taking the KL from both sides of the mixture distribution: $$ JSD(p\\Vert q) = \\frac{1}{2}KL(p\\Vert\\frac{p+q}{2}) + \\frac{1}{2}KL(q\\Vert\\frac{p+q}{2}). $$\nWith this tool in hand, we can understand the loss function from a different perspective and prove that the perfect generator $p_g$ replicates the data space $p_r$. Recall that the optimal discriminator $D^*(x) = \\frac{p_r(x)}{p_r(x)+p_g(x)}$, if we plug this into Equation $\\eqref{eq: gan_loss}$, we get: $$ \\begin{aligned} L(G, D^{*}) \u0026= \\mathbb{E}_{x\\sim p_r(x)}\\left[\\log (D^*(x))\\right] + \\mathbb{E}_{x\\sim p_g(x)}\\left[\\log(1- D^*(x)\\right]\\\\ \u0026= \\int_{x}p_r(x)\\log\\left(\\frac{2\\cdot p_r(x)}{2\\cdot(p_r(x)+p_g(x))}\\right)dx\\\\ \u0026\\phantom{=} + \\int_{x}p_g(x)\\log\\left(\\frac{2\\cdot p_g(x)}{2\\cdot(p_r(x)+p_g(x))}\\right)dx\\\\ \u0026= -2\\log2 + \\int_{x}p_r(x)\\log\\left(\\frac{p_r(x)}{\\frac{p_r(x)+p_g(x)}{2}}\\right)dx\\\\ \u0026\\phantom{=} + \\int_{x}p_g(x)\\log\\left(\\frac{p_g(x)}{\\frac{p_r(x)+p_g(x)}{2}}\\right)dx\\\\ \u0026= -2\\log2 + KL(p_r\\Vert\\frac{p_r+p_g}{2}) + KL(p_g\\Vert\\frac{p_r+p_g}{2})\\\\ \u0026= -2\\log2 + 2JSD(p_r\\Vert p_g). \\end{aligned} $$ Thus, when the discriminator is optimal, the loss function is equivalent to measuring the difference between $p_g$ and $p_r$ with JS divergence. Also, when the generator is optimal, $p_r = p_g$, and $2JSD(p_r, p_g)=0$, so $L(G^*, D^*) = -2\\log2$, which is the global optimal.\nThe Real Cost Function (Arjovsky \u0026 Bottou, 2017) Figure 2: Low dimensional manifolds in high dimension space can hardly have overlaps. We have proved that the optimally trained discriminator should have a maximum cost of $-2\\log2+2JSD(p_r|p_g)$, and with the optimal generator, this cost goes to $-2\\log 2$. However, in practice, the training loss approaches $0$. This implies that $JSD(p_r|p_g)=\\log2$, and the JS-divergence between the two distributions is maxed out.\nThis is because the supports for $p_r$ and $p_g$ lie on low dimensional manifolds. To provide some intuition, consider the data space $\\mathcal{X}$ which contains all possible real-world images. Although the dimension of $\\mathcal{X}$ can be artificially high (e.g. $256\\times256\\times3$), there are pre-existing restrictions placed by nature. For instance, a mammal face usually contains eyes, ears, a nose, a mouth, and a jaw. Thus, the support of $p_r$ is concentrated on a low dimensional manifold. Similarly, since the generator $G(z, \\theta_g): \\mathcal{Z} \\to \\mathcal{X}$ estimates the data space by sampling from a prior distribution $p_z$ with less dimension (e.g. 100) than $\\mathcal{X}$, the support of $p_g$ is also on a low dimensional manifold.\nRecall that if $\\mathcal{X}: \\Omega\\to\\mathbb{R}^n$ is a random variable, then the support of $\\mathcal{X}$ is defined as the closure of the set $\\mathrm{Supp}(x) = {x\\in\\mathbb{R}^n: p_r(x)\u003e0}$. For instance, in our example of GANs, the support of $p_g$ has to be contained in the range of $G(z, \\theta_g)$. In other words, the support of $p_g$ is the set of points in the data space that the generator can produce with non-zero probability.\nDenote $\\mathcal{M}$ as the manifold where the support of $p_r$ lies in, and $\\mathcal{P}$ the manifold where the support of $p_g$ lies in. It can be shown that:\nIf $\\mathcal{M}$ and $\\mathcal{P}$ don’t perfectly align and don’t have full dimensions, then there exists a perfect discriminator $D^{**}: \\mathcal{X}\\to[0,1]$ such that it takes the value $1$ on a set that contains the support of $p_r$ and value $0$ on a set that contains the support of $p_g$. Also, $\\nabla_xD^*(x)=0$. If $\\mathcal{M}$ and $\\mathcal{P}$ don’t perfectly align and don’t have full dimensions, then \\begin{aligned} JSD(p_r|p_g) \u0026= \\log2\\\\ KL(p_r|p_g) \u0026= +\\infty\\\\ KL(p_g|p_r) \u0026= +\\infty. \\end{aligned} Let $J_{\\theta_g} G(z,\\theta_g)$ denote the Jacobian of $G$ with respect to $\\theta_g$. If the perfect discriminator is satisfied, and $|D-D^{**}|\u003c\\epsilon$, and $\\mathbb{E}_{z\\sim p(z)}\\left[|J_{\\theta_g} G(z,\\theta_g)|^2_2\\right]\\leq C^2$, then $$ |\\nabla_{\\theta_g}\\mathbb{E}_{z\\sim p(z)}\\left[\\log(1-D(G(z,\\theta_g)))\\right]|_2 \u003c C\\frac{\\epsilon}{1-\\epsilon}. $$ We will go through each item in the following paragraphs.\nNote that the perfect discriminator $D^{**}$ is different from the optimal discriminator discussed above, which assigns equal probabilities to fake and real samples. In fact, this difference is precisely the reason why in practice, the cost of the discriminator approaches 0. In conjunction with the result in 2, we understand that although the generator is producing realistic looking results, the two underlying distributions $p_r, p_g$ are actually very different and easy for the discriminator to distinguish.\nTo explain the idea in 2 in simpler terms, consider the following four cases between $p_r$ and $p_g$ when calculating $JSD$: \\begin{aligned} p_r(x) \u0026= 0, p_g(x) = 0\\\\ p_r(x) \u0026\\neq 0, p_g(x) = 0 \\\\ p_r(x) \u0026= 0, p_g(x) \\neq 0\\\\ p_r(x) \u0026\\neq 0, p_g(x) \\neq 0 \\end{aligned} The first case does not contribute to $JSD$. The second case is $\\frac{1}{2}\\log\\left(\\frac{p_r}{\\frac{p_r+0}{2}}\\right)=\\frac{1}{2}\\log2$ in $JSD$ calculation. Similarly, the third case contributes $\\frac{1}{2}\\log2$. For the fourth case, since $\\mathcal{M}$ and $\\mathcal{P}$ don’t perfectly align and don’t have full dimensions, for any parts where $p_r(x)$ and $p_g(x)$ overlap, the resulting integral is negligible, so it also does not contribute to $JSD$. To provide further intuition, if the data space is $\\mathbb{R}^3$, and the supports are planes, then it is very unlikely for them to be perfectly aligned; their intersection is most likely a line which does not contribute to the measure (see Figure 2).\nFinally, the result in 3 provides a bound on the generator’s loss when the difference between the discriminator and the perfect discriminator is also bounded. This is also known as the vanishing gradient problem, and explains the instability in GAN training. In fact, when the discriminator is perfect, the gradient provided to the generator approaches $0$: $$\\lim_{|D-D^{**}|\\to0}\\nabla_{\\theta_g}\\mathbb{E}_{z\\sim p(z)}\\left[\\log(1-D(G(z,\\theta_g)))\\right] = 0.$$ This is intuitive as the generator’s loss function depends on the discriminator.\nOverall, this subsection shows that under the original loss function, there exists a perfect discriminator, which easily distinguishes $p_g,p_r$, and provides little signal for the generator to learn.\nWGANs (Arjovsky, Chintala, \u0026 Bottou, 2017) After providing a mathematical framework to dissect GANs, and formally understanding its limitations, Arjovsky and Bottou, this time with the addition of Chintala, borrowed ideas of optimal transport and proposed a new generative model that is easier to train.\nAs someone without a strong mathematical background, I used the following resources to understand the theory behind optimal transport and measure theory, you may find them helpful too:\nAlex Williams - A Short Introduction to Optimal Transport and Wasserstein Distance Marco Cuturi - A Primer on Optimal Transport Lilian Weng - From GAN to WGAN Vincent Herrmann - Wasserstein GAN and the Kantorovich-Rubinstein Duality Peyré and Cuturi - Computational Optimal Transport (if you’d like to dive deeper) The Wasserstein Distance One important feature of optimal transport is that it can be used to define a continuous metric on a space of probability measures. If we compare distributions $p_r$ and $p_g$ using the minimum $L^p$ cost necessary for an optimal transport plan to shift from $p_r$ to $p_g$, this quantity is called the Wasserstein distance $W(p_r, p_g)$, and it is defined as: $$ W(p_r, p_g) = \\inf_{\\gamma \\in \\Pi(p_r, p_g)} \\mathbb{E}_{(x, y) \\sim \\gamma} [\\lVert x - y \\rVert], $$ where $\\Pi(p_r, p_g)$ is the set of all possible joint probability distributions between $p_r$ and $p_g$, or all possible transport plans (Alex Williams’ post contains a step-by-step example on calculating the transport plan costs).\nBy using the Kantorovich-Rubinstein duality, it can be reformulated as: $$ W(p_r, p_g) = \\sup_{\\lVert h \\rVert_{L \\leq 1}} \\mathbb{E}_{x \\sim p_r} [h(x)] - \\mathbb{E}_{x \\sim p_g} [h(x)], $$ where the supremum is taken over all $1$-Lipschitz functions. Intuitively, the duality expresses the Wasserstein distance between $p_r$ and $p_g$ as the largest difference in expectations of certain functions $h$ that satisfy the Lipschitz constraint. The dual formulation is often easier to compute since it only involves optimizing over a set of functions rather than a set of joint probability measures.\nThe idea of behind WGANs is very simple: optimize the parameters by solving the $W(p_r, p_g)$ instead. Doing so avoids the vanishing gradient we mentioned above, even when the supports for $p_r$ and $p_g$ lie on low dimensional manifolds.\nWGAN Implementation Concretely, the discriminator $D$ is replaced by a critic $C$ that estimates the Wasserstein distance between the real data distribution from the fake one: $$ \\max_{C\\in \\mathcal{C}} \\mathbb{E}_{x\\sim p_r(x)}[C(x)] - \\mathbb{E}_{x\\sim p_g(x)}[C(x)], $$ where $\\mathcal{C}$ is the set of $1$-Lipschitz functions.\nThe generator still tries to fool the critic by minimizing the estimated Wasserstein distance: $$ \\min_G \\mathbb{E}_{z\\sim p_z(z)}[C(G(z))]. $$ The overall loss function is now: $$ \\begin{equation}\\label{eq: wgan_loss} \\min_{G}\\max_{C\\in \\mathcal{C}} \\mathbb{E}_{x\\sim p_r(x)}[C(x)] - \\mathbb{E}_{z\\sim p_z(z)}[C(G(z))]. \\end{equation} $$\nCompared to the original GAN loss (equation $\\eqref{eq: gan_loss}$), this loss function seems simpler, and it actually is! To implement WGAN, we simply remove the final activation function from the discriminator, so that instead of measuring the probability, we output a scalar value (e.g. $[-1, 1]$) from the final linear layer directly which corresponds to the estimated distribution distance. In other words, the only architectural difference between GANs and WGANs is the lack of a sigmoid activation function in the critic.\nOf course, we also need to enforce the Lipschitz constraint. The original WGAN paper proposes to address this through weight clipping: by simply clipping the weights of the critic to a compact set $[−c, c]$ during training. Another prominent work in this direction is gradient penalty by Gulrajani et al., 2017, which penalizes the norm of gradient with respect to its input.\nKaggle Notebook on Toy Examples (Link) I wanted to play with GANs and WGANs on some toy examples. In this notebook, I train and compare each algorithm on 2D Gaussian and geometric shapes. The implementation is done in TensorFlow as a practice for me, so feel free to comment and leave suggestions.\nThe crux of the implementation is very simple:\nimport tensorflow as tf from tensorflow import keras import keras.backend as K from keras import layers from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Activation from keras.models import Sequential, Model from keras.constraints import MaxNorm cross_entropy = keras.losses.BinaryCrossentropy(from_logits=True) # GAN losses def discriminator_loss_fn(real_output, fake_output): real_loss = cross_entropy(tf.ones_like(real_output), real_output) fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output) total_loss = real_loss + fake_loss return total_loss def gan_generator_loss(fake_output): return cross_entropy(tf.ones_like(fake_output), fake_output) # WGAN losses def critic_loss_fn(real_output, fake_output): return tf.reduce_mean(fake_output) - tf.reduce_mean(real_output) # equation 2 def wgan_generator_loss(fake_output): return -tf.reduce_mean(fake_output) # generator update does not depend on the first term in equation 2 # Model Builders, simple feedforward networks with 2 hidden layers def build_generator(hidden_dim, latent_dim, output_dim=2): model = Sequential([ Input(shape=(latent_dim,)), Dense(hidden_dim, activation='relu'), Dense(hidden_dim, activation='relu'), Dense(output_dim, activation='linear') ]) return model def build_discriminator(hidden_dim, lr, input_dim=2): model = Sequential([ Input(shape=(input_dim,)), Dense(hidden_dim, activation='relu'), Dense(hidden_dim, activation='relu'), Dense(1) # using cross entropy from logits, no activation ]) return model # notice how the implementation is the same for discriminator and critic, except critic has added weight clipping def build_critic(hidden_dim, lr, input_dim=2, clip_value=0.01): const = MaxNorm(clip_value) # weight clipping model = Sequential([ Input(shape=(input_dim,)), Dense(hidden_dim, activation='relu', kernel_constraint=const), Dense(hidden_dim, activation='relu', kernel_constraint=const), Dense(1, kernel_constraint=const) ]) return model # per-iteration/batch training function for both GAN and WGAN @tf.function def train_gan_step( model, X_train, dis_iter=5, batch_size=64, latent_dim=2, ): dis, generator = model['dis'], model['gen'] dis_loss, generator_loss = model['dis_loss'], model['gen_loss'] dis_opt, generator_opt = model['dis_opt'], model['gen_opt'] # Loop over discriminator/critic training steps (dis_iter times) for _ in range(dis_iter): noise = tf.random.normal([batch_size, latent_dim]) batch_idx = tf.random.shuffle(tf.range(X_train.shape[0]))[:batch_size] sample_batch_inner = tf.gather(X_train, batch_idx) with tf.GradientTape() as disc_tape: generated_samples = generator(noise, training=False) real_output = dis(sample_batch_inner, training=True) fake_output_gan = dis(generated_samples, training=True) disc_loss = dis_loss(real_output, fake_output_gan) gradients_of_discriminator = disc_tape.gradient(disc_loss, dis.trainable_variables) dis_opt.apply_gradients(zip(gradients_of_discriminator, dis.trainable_variables)) # Train generator noise = tf.random.normal([batch_size, latent_dim]) with tf.GradientTape() as gen_tape: generated_samples = generator(noise, training=True) fake_output = dis(generated_samples, training=False) gen_loss = generator_loss(fake_output) gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables) generator_opt.apply_gradients(zip(gradients_of_generator, generator.trainable_variables)) return During training, I expected WGANs to be less sensitive to hyperparameter choices than GANs, especially on these simple 2D examples. However, the weight clipping value $c$ had a significant impact on the learning process.\nThe original WGAN paper had $c=0.01$, but this made the model update steps way too small, and resulted in converge slower than expected. Instead, I found that $c=0.5$ worked best. I have included a hyperparameter study pipeline in the notebook for readers to explore.\nIt seems that having multiple discriminator updates per generator update is also beneficial for GAN training.\nFigure 3: Learning on an 8-Gaussian dataset. It is cool how the model is warping the cloud of points into the circular shape. Figure 4: Learning on a crescent moon dataset. WGAN is visibly more stable during training Figure 5: Losses and Gradients on the crescent moon dataset. WGAN gradient (bottom right) is much more stable compared to the oscillating GAN gradient (bottom left). Thank you for reading! If you found this post helpful in your own writing or research, please cite it as:\n@article{bai2025gan, title={The Story behind WGAN}, author={Bai, Mark}, journal={rdh1115.github.io}, year={2025}, url={https://rdh1115.github.io/posts/literature/gan-wgan/} } ",
  "wordCount" : "3038",
  "inLanguage": "en",
  "datePublished": "2025-01-21T00:00:00Z",
  "dateModified": "2025-01-16T17:14:20-05:00",
  "author":{
    "@type": "Person",
    "name": "Mark Bai"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://rdh1115.github.io/posts/literature/gan-wgan/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "rdh1115 Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://rdh1115.github.io/icons/brain_128.png"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://rdh1115.github.io/" accesskey="h" title="rdh1115 Blog (Alt + H)">rdh1115 Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://rdh1115.github.io/" title="Posts">
                    <span>Posts</span>
                </a>
            </li>
            <li>
                <a href="https://rdh1115.github.io/archives/" title="Archive">
                    <span>Archive</span>
                </a>
            </li>
            <li>
                <a href="https://rdh1115.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://rdh1115.github.io/tags/" title="Tags">
                    <span>Tags</span>
                </a>
            </li>
            <li>
                <a href="https://rdh1115.github.io/about/" title="About">
                    <span>About</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
    <header class="post-header">
        <div class="breadcrumbs"><a href="https://rdh1115.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://rdh1115.github.io/posts/">Posts</a>&nbsp;»&nbsp;<a href="https://rdh1115.github.io/posts/literature/">Literature</a></div>
        <h1 class="post-title entry-hint-parent">
            The Story behind WGAN
        </h1>
        <div class="post-description">
            An introduction to GAN and WGAN (code examples included).
        </div>
        <div class="post-meta"><span title='2025-01-21 00:00:00 +0000 UTC'>January 21, 2025</span>&nbsp;·&nbsp;Estimated Reading Time: 50 min&nbsp;·&nbsp;Mark Bai&nbsp;|&nbsp;<a href="https://github.com/rdh1115/rdh1115.github.io/issues/new" rel="noopener noreferrer" target="_blank">Suggest Changes</a>

</div>
    </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul><ul>
                <li>
                    <a href="#gans" aria-label="GANs">GANs</a><ul>
                        
                <li>
                    <a href="#cool-history" aria-label="Cool History">Cool History</a></li>
                <li>
                    <a href="#gan-architecture-goodfellow-et-al-2014httpsproceedingsneuripsccpaper_filespaper2014file5ca3e9b122f61f8f06494c97b1afccf3-paperpdf" aria-label="GAN Architecture (Goodfellow et al., 2014)">GAN Architecture (Goodfellow et al., 2014)</a></li>
                <li>
                    <a href="#how-to-train-gans" aria-label="How to train GANs">How to train GANs</a><ul>
                        
                <li>
                    <a href="#the-optimal-discriminator-and-generator" aria-label="The Optimal Discriminator and Generator">The Optimal Discriminator and Generator</a></li>
                <li>
                    <a href="#tangent-on-kl--js-divergence" aria-label="Tangent on KL &amp; JS Divergence">Tangent on KL &amp; JS Divergence</a></li></ul>
                </li>
                <li>
                    <a href="#the-real-cost-function-arjovsky--bottou-2017httpsopenreviewnetpdfidhk4_qw5xe" aria-label="The Real Cost Function (Arjovsky &amp; Bottou, 2017)">The Real Cost Function (Arjovsky &amp; Bottou, 2017)</a></li></ul>
                </li></ul>
                    
                <li>
                    <a href="#wgans-arjovsky-chintala--bottou-2017httpsarxivorgpdf170107875" aria-label="WGANs (Arjovsky, Chintala, &amp; Bottou, 2017)">WGANs (Arjovsky, Chintala, &amp; Bottou, 2017)</a><ul>
                        
                <li>
                    <a href="#the-wasserstein-distance" aria-label="The Wasserstein Distance">The Wasserstein Distance</a></li>
                <li>
                    <a href="#wgan-implementation" aria-label="WGAN Implementation">WGAN Implementation</a></li></ul>
                </li>
                <li>
                    <a href="#kaggle-notebook-on-toy-examples-linkhttpswwwkagglecomcodemarkbaigan-wgan" aria-label="Kaggle Notebook on Toy Examples (Link)">Kaggle Notebook on Toy Examples (Link)</a>
                </li>
            </ul>
        </div>
    </details>
</div>

    <div class="post-content"><p>This post explores the theory and some follow-up papers of  one of the most influential machine learning papers:
<a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">Generative Adversarial Networks</a> (GANs).
Contrary to other deep learning models, I find that generative models are supported by more rigorous mathematics that are easily digestible.</p>
<p>As we understand the theory behind GANs (mostly through the paper by <a href="https://openreview.net/pdf?id=Hk4_qw5xe">Arjovsky and Bottou, 2017</a>),
we will recognize its limitations and the reason behind its instability.
This naturally leads us to
<a href="https://arxiv.org/pdf/1701.07875">Wasserstein Generative Adversarial Networks</a> (WGANs),
which apply useful concepts from <a href="https://en.wikipedia.org/wiki/Transportation_theory_%28mathematics%29">Optimal Transport</a> (OT).</p>
<p>Since these papers are quite &ldquo;old&rdquo; by machine learning standards, there are many blog posts that already discuss them.
The following is my own understanding plus some parts I find missing in other posts.
A Kaggle notebook is also provided to compare the algorithms learning on a toy example:
<a href="https://www.kaggle.com/code/markbai/gan-wgan/">Kaggle Notebook Link</a></p>
<h2 id="gans">GANs<a hidden class="anchor" aria-hidden="true" href="#gans">#</a></h2>
<h3 id="cool-history">Cool History<a hidden class="anchor" aria-hidden="true" href="#cool-history">#</a></h3>
<p>The story is that GAN was conceived at a bar in Montréal (Les 3 Brasseurs) by Ian Goodfellow during his Ph.D. studies. At the bar, he proposed GAN to his friends, but quickly faced skepticism.</p>
<p>The idea of jointly training a pair of networks against each other seemed too difficult when training just one network was difficult enough.
Perhaps due to the influence of alcohol, he was still confident, so he headed home, coded up GAN,
and produced amazing results on <a href="https://yann.lecun.com/exdb/mnist/">MNIST</a> (a handwritten digit recognition dataset).</p>
<p>As of today, the seminal paper published in NeurIPS has over 75,000 citations, and has become a cornerstone in the field of unsupervised learning.</p>
<h3 id="gan-architecture-goodfellow-et-al-2014httpsproceedingsneuripsccpaper_filespaper2014file5ca3e9b122f61f8f06494c97b1afccf3-paperpdf">GAN Architecture (<a href="https://proceedings.neurips.cc/paper_files/paper/2014/file/5ca3e9b122f61f8f06494c97b1afccf3-Paper.pdf">Goodfellow et al., 2014</a>)<a hidden class="anchor" aria-hidden="true" href="#gan-architecture-goodfellow-et-al-2014httpsproceedingsneuripsccpaper_filespaper2014file5ca3e9b122f61f8f06494c97b1afccf3-paperpdf">#</a></h3>
<p>GANs learn the latent distribution of the unlabeled data through a pair of networks
(the generator and the discriminator) that are competing against each other.
An analogy is used in the original paper: the generator is a team of counterfeiters that produces fake currency,
while the discriminator is the police trying to detect forgery.
When both networks are optimal, the generator is able to produce counterfeit currency that is indistinguishable from the
real ones.</p>
<figure id="fig:gan" style="text-align: center;">
    <img src="./adversarial_net.png" alt="GAN architecture" style="display: block; margin: 0 auto;">
    <figcaption style="text-align: left; margin-top: 0.5rem;">Figure 1: A GAN consists of two components: 
    the discriminator $D$ outputs the probability that a given sample is real, 
    and the generator $G$ produces synthetic samples given a latent variable $z$ sampled from the base distribution, e.g. $z \sim \mathcal{N}(0,1)$. 
    The discriminator parameters $\theta_d$ are updated to assigns high probability to real samples and low probability 
    to synthetic samples, while the generator parameters $\theta_g$ are updated to "fool" the discriminator into assigning high 
    probabilities to the synthetic samples.</figcaption>
</figure>
<p>First, let&rsquo;s define $p_z, p_g, p_r$ as the probability distributions of the
latent variable $z$, the generator, and real samples respectively.</p>
<p>The discriminator $D(x,\theta_d)\to [0, 1]$ outputs a scalar that represents the probability that $x$ came from $p_r$ rather than $p_g$.
The generator $G(z, \theta_g)$ then learns a mapping from $z$ to the data space.
In other words, it is learning $p_g$ over data $x$, where $x\sim p_r(x)$.</p>
<p>$D$ is trained in a binary classification fashion. It maximizes the probability of assigning the correct label to both
real samples $x$ and fake samples $x&rsquo; = G(z)$.
This is equivalent to maximizing
$$\max_D \mathbb{E}_{x\sim p_r(x)}\left[\log (D(x))\right] +\mathbb{E}_{z\sim p_z(z)}\left[\log(1- D(G(z)))\right].$$</p>
<p>The generator then minimizes the probability of the discriminator assigning the correct label to the fake samples:
$$\min_G \mathbb{E}_{z\sim p_z(z)}\left[\log(1- D(G(z)))\right].$$
In other words, they are playing a MinMax game with the following loss function:
$$
\begin{equation}\label{eq: gan_loss}
\min_{G}\max_{D} L(G, D) =
\mathbb{E}_{x\sim p_r(x)}\left[\log (D(x))\right] +
\mathbb{E}_{z\sim p_z(z)}\left[\log(1- D(G(z)))\right]
\end{equation}
$$</p>
<h3 id="how-to-train-gans">How to train GANs<a hidden class="anchor" aria-hidden="true" href="#how-to-train-gans">#</a></h3>
<p>Since the discriminator and the generator are playing a two-player non-cooperative game,
training them can be difficult, and similar to finding the Nash equilibrium (<a href="https://arxiv.org/pdf/1606.03498">Salimans et al., 2016</a>).</p>
<p>In practice, this is traditionally done with the following pipeline: in each training loop, fix the generator and update the discriminator for $k$ steps,
then fix the discriminator and update the generator for 1 step.</p>
<p>To update the discriminator, we fix the generator and isolate the $\max_{D} L(G, D)$ part of Equation $\eqref{eq: gan_loss}$:
$$
\begin{aligned}
L(\theta_d)
&amp; = \mathbb{E}_{x\sim p_r(x)}\left[\log (D(x, \theta_d))\right] + \mathbb{E}_{z\sim p_z(z)}\left[\log(1- D(G^*(z), \theta_d))\right] \\
&amp; \approx \frac{1}{m}\sum_{i=1}^m\left[\log (D(x_i, \theta_d))\right] + \frac{1}{n}\sum_{j=1}^n\left[ \log( 1 - D ( G^* (z_j), \theta_d)) \right],
\end{aligned}
$$
where $m$ represents the number of real examples, $n$ represents the number of fake examples, and $G^*(z)$ represents the fixed generator.<br>
To update the generator, we use the following loss function:
$$
\begin{aligned}
L(\theta_g)
&amp; = \left(\mathbb{E}_{x\sim p_r(x)}\left[\log (D^*(x))\right] + \mathbb{E}_{z\sim p_z(z)}\left[\log(1- D^*(G(z, \theta_g)))\right]\right) \\
&amp; \approx \frac{1}{n}\sum_{j=1}^n\left[ \log ( 1 - D^* (G(z_j, \theta_g)))\right]
\end{aligned}.
$$
Note that we remove the first term since it is not related to $G(z, \theta_g)$.</p>
<h4 id="the-optimal-discriminator-and-generator">The Optimal Discriminator and Generator<a hidden class="anchor" aria-hidden="true" href="#the-optimal-discriminator-and-generator">#</a></h4>
<p>It is intuitive that in theory, the perfect generator replicates the entire data space,
in other words, $p_g = p_r$ (see proof <a href="/posts/literature/gan-wgan/#tangent-on-kl--js-divergence">below</a>). It is natural then to think that the perfect discriminator can always differentiate between real and synthetic samples, however
in theory, the best discriminator achieves random guessing.</p>
<p>Lil&rsquo;Log provides a great breakdown on the <a href="https://lilianweng.github.io/posts/2017-08-20-gan/#what-is-the-optimal-value-for-d">math behind this</a>.
The general idea is that if we take the derivative of the discriminator&rsquo;s loss function with a fixed generator, and set it to zero,
$D^*(x) = \frac{p_r(x)}{p_r(x)+p_g(x)}$. And since the perfect generator enables $p_g = p_r$,
$D^*(x) = \frac{1}{2}$.</p>
<p>Given $G^*(z, \theta_g)$ such that $p_r = p_g$, and $D^*(x, \theta_d)$ such that $D^*(x) = \frac{1}{2}$, we can
derive the global minimum of the loss function:
$$
\begin{aligned}
L(G^*, D^*)
&amp;= \mathbb{E}_{x\sim p_r(x)}\left[-\log2\right] +\mathbb{E}_{x\sim p_g(x)}\left[-\log2\right]\\
&amp;= -2\log2
\end{aligned}
$$
Thus, the best possible value of $L(G, D)$ is $-2\log2$.</p>
<h4 id="tangent-on-kl--js-divergence">Tangent on KL &amp; JS Divergence<a hidden class="anchor" aria-hidden="true" href="#tangent-on-kl--js-divergence">#</a></h4>
<p><a href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler (KL) divergence</a>
is one of the most commonly used measures in machine learning for comparing two probability distributions.
Given distributions $p, q$,
it measures how different $q$ is from $p$ with the following formulation:
$$
KL(p\Vert q) = \int_{x}p(x)\log\frac{p(x)}{q(x)}dx.
$$
Usually, $p$ is the true distribution, and $q$ is the model. The interpretation from information theory is that
KL divergence measure the extra information gain (relative entropy) when switching from $q$ to $p$.</p>
<p>There are many limitations to KL divergence, one of the most being its asymmetry.
If we explore the Wikipedia page for KL divergence, we will find that the
<a href="https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence">Jensen-Shannon (JS) divergence</a> addresses this issue by
taking the KL from both sides of the mixture distribution:
$$
JSD(p\Vert q) = \frac{1}{2}KL(p\Vert\frac{p+q}{2}) + \frac{1}{2}KL(q\Vert\frac{p+q}{2}).
$$</p>
<p>With this tool in hand, we can understand the loss function from a different perspective
and prove that the perfect generator $p_g$ replicates the data space $p_r$.
Recall that the optimal discriminator $D^*(x) = \frac{p_r(x)}{p_r(x)+p_g(x)}$, if we plug this into Equation $\eqref{eq: gan_loss}$, we get:
$$
\begin{aligned}
L(G, D^{*})
&amp;= \mathbb{E}_{x\sim p_r(x)}\left[\log (D^*(x))\right] +
\mathbb{E}_{x\sim p_g(x)}\left[\log(1- D^*(x)\right]\\
&amp;= \int_{x}p_r(x)\log\left(\frac{2\cdot p_r(x)}{2\cdot(p_r(x)+p_g(x))}\right)dx\\
&amp;\phantom{=} + \int_{x}p_g(x)\log\left(\frac{2\cdot p_g(x)}{2\cdot(p_r(x)+p_g(x))}\right)dx\\
&amp;= -2\log2 + \int_{x}p_r(x)\log\left(\frac{p_r(x)}{\frac{p_r(x)+p_g(x)}{2}}\right)dx\\
&amp;\phantom{=} + \int_{x}p_g(x)\log\left(\frac{p_g(x)}{\frac{p_r(x)+p_g(x)}{2}}\right)dx\\
&amp;= -2\log2 + KL(p_r\Vert\frac{p_r+p_g}{2}) + KL(p_g\Vert\frac{p_r+p_g}{2})\\
&amp;= -2\log2 + 2JSD(p_r\Vert p_g).
\end{aligned}
$$
Thus, when the discriminator is optimal, the loss function is equivalent to measuring the difference between $p_g$ and $p_r$ with JS divergence.
Also, when the generator is optimal, $p_r = p_g$, and $2JSD(p_r, p_g)=0$, so $L(G^*, D^*) = -2\log2$, which is the global optimal.</p>
<h3 id="the-real-cost-function-arjovsky--bottou-2017httpsopenreviewnetpdfidhk4_qw5xe">The Real Cost Function (<a href="https://openreview.net/pdf?id=Hk4_qw5xe">Arjovsky &amp; Bottou, 2017</a>)<a hidden class="anchor" aria-hidden="true" href="#the-real-cost-function-arjovsky--bottou-2017httpsopenreviewnetpdfidhk4_qw5xe">#</a></h3>
<figure id="fig:manifold" style="text-align: center;">
    <img src="./manifold.png" alt="manifold" style="display: block; margin: 0 auto;">
    <figcaption style="text-align: left; margin-top: 0.5rem;">Figure 2: Low dimensional manifolds in 
    high dimension space can hardly have overlaps.</figcaption>
</figure>
<p>We have proved that the optimally trained discriminator should have a maximum cost of $-2\log2+2JSD(p_r|p_g)$,
and with the optimal generator, this cost goes to $-2\log 2$.
However, in practice, <strong>the training loss approaches $0$</strong>.
This implies that $JSD(p_r|p_g)=\log2$, and the JS-divergence between the two distributions is maxed out.</p>
<p>This is because the supports for $p_r$ and $p_g$ lie on low dimensional manifolds.
To provide some intuition, consider the data space $\mathcal{X}$ which contains all possible real-world images.
Although the dimension of $\mathcal{X}$ can be artificially high (e.g. $256\times256\times3$),
there are pre-existing restrictions placed by nature.
For instance, a mammal face usually contains eyes, ears, a nose, a mouth, and a jaw.
Thus, the support of $p_r$ is concentrated on a low dimensional manifold.
Similarly, since the generator $G(z, \theta_g): \mathcal{Z} \to \mathcal{X}$ estimates the data space by sampling from a prior distribution $p_z$
with less dimension (e.g. 100) than $\mathcal{X}$, the support of $p_g$ is also on a low dimensional manifold.</p>
<p>Recall that if $\mathcal{X}: \Omega\to\mathbb{R}^n$ is a random variable, then the support of $\mathcal{X}$ is
defined as the closure of the set $\mathrm{Supp}(x) = {x\in\mathbb{R}^n: p_r(x)&gt;0}$.
For instance, in our example of GANs, the support of $p_g$ has to be contained in the range of $G(z, \theta_g)$.
In other words, the support of $p_g$ is the set of points in the data space that the generator can produce with non-zero probability.</p>
<p>Denote $\mathcal{M}$ as the manifold where the support of $p_r$ lies in, and $\mathcal{P}$ the manifold where the support of $p_g$ lies in.
It can be shown that:</p>
<ol>
<li>If $\mathcal{M}$ and $\mathcal{P}$ don&rsquo;t perfectly align and don&rsquo;t have full dimensions,
then there exists a perfect discriminator $D^{**}: \mathcal{X}\to[0,1]$
such that it takes the value $1$ on a set that contains the support of $p_r$ and value $0$ on a set that contains
the support of $p_g$. Also, $\nabla_xD^*(x)=0$.</li>
<li>If $\mathcal{M}$ and $\mathcal{P}$ don&rsquo;t perfectly align and don&rsquo;t have full dimensions, then
\begin{aligned}
JSD(p_r|p_g) &amp;= \log2\\
KL(p_r|p_g) &amp;= +\infty\\
KL(p_g|p_r) &amp;= +\infty.
\end{aligned}</li>
<li>Let $J_{\theta_g} G(z,\theta_g)$ denote the Jacobian of $G$ with respect to $\theta_g$.
If the perfect discriminator is satisfied, and $|D-D^{**}|&lt;\epsilon$, and
$\mathbb{E}_{z\sim p(z)}\left[|J_{\theta_g} G(z,\theta_g)|^2_2\right]\leq C^2$, then
$$
|\nabla_{\theta_g}\mathbb{E}_{z\sim p(z)}\left[\log(1-D(G(z,\theta_g)))\right]|_2 &lt; C\frac{\epsilon}{1-\epsilon}.
$$</li>
</ol>
<p>We will go through each item in the following paragraphs.<br>
Note that the perfect discriminator $D^{**}$ is different from the optimal discriminator discussed <a href="/posts/literature/gan-wgan/#the-optimal-discriminator-and-generator">above</a>,
which assigns equal probabilities to fake and real samples.
In fact, this difference is precisely the reason why in practice, the cost of the discriminator approaches 0.
In conjunction with the result in 2, we understand that although the generator is producing realistic looking results,
the two underlying distributions $p_r, p_g$ are actually very different and easy for the discriminator to distinguish.</p>
<p>To explain the idea in 2 in simpler terms, consider the following four cases between $p_r$ and $p_g$ when calculating $JSD$:
\begin{aligned}
p_r(x) &amp;= 0, p_g(x) = 0\\
p_r(x) &amp;\neq 0, p_g(x) = 0 \\
p_r(x) &amp;= 0, p_g(x) \neq 0\\
p_r(x) &amp;\neq 0, p_g(x) \neq 0
\end{aligned}
The first case does not contribute to $JSD$.
The second case is $\frac{1}{2}\log\left(\frac{p_r}{\frac{p_r+0}{2}}\right)=\frac{1}{2}\log2$ in $JSD$ calculation.
Similarly, the third case contributes $\frac{1}{2}\log2$. <br>
For the fourth case, since $\mathcal{M}$ and $\mathcal{P}$ don&rsquo;t perfectly align and don&rsquo;t have full dimensions,
for any parts where $p_r(x)$ and $p_g(x)$ overlap, the resulting integral is negligible, so it also does not contribute to $JSD$.
To provide further intuition, if the data space is $\mathbb{R}^3$,
and the supports are planes, then it is very unlikely for them to be perfectly aligned;
their intersection is most likely a line which does not contribute to the measure (see <a href="/posts/literature/gan-wgan/#fig:manifold">Figure 2</a>).</p>
<iframe src="/manifold.html" width="100%" height="600px" frameborder="0"></iframe>
<p>Finally, the result in 3 provides a bound on the generator&rsquo;s loss
when the difference between the discriminator and the perfect discriminator is also bounded.
This is also known as the vanishing gradient problem, and explains the instability in GAN training.
In fact, when the discriminator is perfect, the gradient provided to the generator approaches $0$:
$$\lim_{|D-D^{**}|\to0}\nabla_{\theta_g}\mathbb{E}_{z\sim p(z)}\left[\log(1-D(G(z,\theta_g)))\right] = 0.$$
This is intuitive as the generator&rsquo;s loss function depends on the discriminator.</p>
<p>Overall, this subsection shows that under the original loss function, there exists a perfect discriminator,
which easily distinguishes $p_g,p_r$, and provides little signal for the generator to learn.</p>
<h1 id="wgans-arjovsky-chintala--bottou-2017httpsarxivorgpdf170107875">WGANs (<a href="https://arxiv.org/pdf/1701.07875">Arjovsky, Chintala, &amp; Bottou, 2017</a>)<a hidden class="anchor" aria-hidden="true" href="#wgans-arjovsky-chintala--bottou-2017httpsarxivorgpdf170107875">#</a></h1>
<p>After providing a mathematical framework to dissect GANs, and formally understanding its limitations,
Arjovsky and Bottou, this time with the addition of Chintala, borrowed ideas of optimal transport and
proposed a new generative model that is easier to train.</p>
<p>As someone without a strong mathematical background,
I used the following resources to understand the theory behind optimal transport and measure theory,
you may find them helpful too:</p>
<ul>
<li><a href="https://alexhwilliams.info/itsneuronalblog/2020/10/09/optimal-transport/">Alex Williams - A Short Introduction to Optimal Transport and Wasserstein Distance</a></li>
<li><a href="https://youtu.be/6iR1E6t1MMQ?si=haesqqfJXLJNkybq">Marco Cuturi - A Primer on Optimal Transport</a></li>
<li><a href="https://lilianweng.github.io/posts/2017-08-20-gan/#wasserstein-gan-wgan">Lilian Weng - From GAN to WGAN</a></li>
<li><a href="https://vincentherrmann.github.io/blog/wasserstein/">Vincent Herrmann - Wasserstein GAN and the Kantorovich-Rubinstein Duality</a></li>
<li><a href="https://arxiv.org/pdf/1803.00567">Peyré and Cuturi - Computational Optimal Transport</a> (if you&rsquo;d like to dive deeper)</li>
</ul>
<h2 id="the-wasserstein-distance">The Wasserstein Distance<a hidden class="anchor" aria-hidden="true" href="#the-wasserstein-distance">#</a></h2>
<p>One important feature of optimal transport is that it can be used to define a continuous metric on a space of probability measures.
If we compare distributions $p_r$ and $p_g$ using the minimum $L^p$ cost necessary for an optimal transport plan to
shift from $p_r$ to $p_g$, this quantity is called the Wasserstein distance $W(p_r, p_g)$, and it is defined as:
$$
W(p_r, p_g) = \inf_{\gamma \in \Pi(p_r, p_g)} \mathbb{E}_{(x, y) \sim \gamma} [\lVert x - y \rVert],
$$
where $\Pi(p_r, p_g)$ is the set of all possible joint probability distributions between $p_r$ and $p_g$,
or all possible transport plans (Alex Williams&rsquo; post contains a step-by-step example on calculating the transport plan costs).<br>
By using the Kantorovich-Rubinstein duality, it can be reformulated as:
$$
W(p_r, p_g) = \sup_{\lVert h \rVert_{L \leq 1}} \mathbb{E}_{x \sim p_r} [h(x)] - \mathbb{E}_{x \sim p_g} [h(x)],
$$
where the supremum is taken over all $1$-Lipschitz functions.
Intuitively, the duality expresses the Wasserstein distance between $p_r$ and $p_g$
as the largest difference in expectations of certain functions $h$ that satisfy the Lipschitz constraint.
The dual formulation is often easier to compute since it only involves optimizing over a set of functions
rather than a set of joint probability measures.</p>
<p>The idea of behind WGANs is very simple: optimize the parameters by solving the $W(p_r, p_g)$ instead.
Doing so avoids the vanishing gradient we mentioned above,
even when the supports for $p_r$ and $p_g$ lie on low dimensional manifolds.</p>
<h2 id="wgan-implementation">WGAN Implementation<a hidden class="anchor" aria-hidden="true" href="#wgan-implementation">#</a></h2>
<p>Concretely, the discriminator $D$ is replaced by a critic $C$ that estimates the Wasserstein distance between the real data distribution from the fake one:
$$
\max_{C\in \mathcal{C}} \mathbb{E}_{x\sim p_r(x)}[C(x)] - \mathbb{E}_{x\sim p_g(x)}[C(x)],
$$
where $\mathcal{C}$ is the set of $1$-Lipschitz functions.<br>
The generator still tries to fool the critic by minimizing the estimated Wasserstein distance:
$$
\min_G \mathbb{E}_{z\sim p_z(z)}[C(G(z))].
$$
The overall loss function is now:
$$
\begin{equation}\label{eq: wgan_loss}
\min_{G}\max_{C\in \mathcal{C}}
\mathbb{E}_{x\sim p_r(x)}[C(x)] - \mathbb{E}_{z\sim p_z(z)}[C(G(z))].
\end{equation}
$$</p>
<p>Compared to the original GAN loss (equation $\eqref{eq: gan_loss}$), this loss function seems simpler, and it actually is!
To implement WGAN, we simply remove the final activation function from the discriminator,
so that instead of measuring the probability, we output a scalar value (e.g. $[-1, 1]$) from the final linear layer directly which corresponds to the estimated distribution distance.
In other words, the only architectural difference between GANs and WGANs is the lack of a sigmoid activation function in the critic.</p>
<p>Of course, we also need to enforce the Lipschitz constraint. The original WGAN paper proposes to address this through weight clipping:
by simply clipping the weights of the critic to a compact set $[−c, c]$ during training.
Another prominent work in this direction is gradient penalty by <a href="https://proceedings.neurips.cc/paper_files/paper/2017/file/892c3b1c6dccd52936e27cbd0ff683d6-Paper.pdf">Gulrajani et al., 2017</a>,
which penalizes the norm of gradient with respect to its input.</p>
<h1 id="kaggle-notebook-on-toy-examples-linkhttpswwwkagglecomcodemarkbaigan-wgan">Kaggle Notebook on Toy Examples (<a href="https://www.kaggle.com/code/markbai/gan-wgan/">Link</a>)<a hidden class="anchor" aria-hidden="true" href="#kaggle-notebook-on-toy-examples-linkhttpswwwkagglecomcodemarkbaigan-wgan">#</a></h1>
<p>I wanted to play with GANs and WGANs on some toy examples.
In this notebook, I train and compare each algorithm on 2D Gaussian and geometric shapes.
The implementation is done in TensorFlow as a practice for me, so feel free to comment and leave suggestions.</p>
<p>The crux of the implementation is very simple:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">tensorflow</span> <span class="kn">import</span> <span class="n">keras</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="kn">import</span> <span class="nn">keras.backend</span> <span class="k">as</span> <span class="nn">K</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras</span> <span class="kn">import</span> <span class="n">layers</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.layers</span> <span class="kn">import</span> <span class="n">Input</span><span class="p">,</span> <span class="n">Dense</span><span class="p">,</span> <span class="n">Reshape</span><span class="p">,</span> <span class="n">Flatten</span><span class="p">,</span> <span class="n">Dropout</span><span class="p">,</span> <span class="n">Activation</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.models</span> <span class="kn">import</span> <span class="n">Sequential</span><span class="p">,</span> <span class="n">Model</span>
</span></span><span class="line"><span class="cl"><span class="kn">from</span> <span class="nn">keras.constraints</span> <span class="kn">import</span> <span class="n">MaxNorm</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">cross_entropy</span> <span class="o">=</span> <span class="n">keras</span><span class="o">.</span><span class="n">losses</span><span class="o">.</span><span class="n">BinaryCrossentropy</span><span class="p">(</span><span class="n">from_logits</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># GAN losses</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">discriminator_loss_fn</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">real_loss</span> <span class="o">=</span> <span class="n">cross_entropy</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">real_output</span><span class="p">),</span> <span class="n">real_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">fake_loss</span> <span class="o">=</span> <span class="n">cross_entropy</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">fake_output</span><span class="p">),</span> <span class="n">fake_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">real_loss</span> <span class="o">+</span> <span class="n">fake_loss</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">total_loss</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">gan_generator_loss</span><span class="p">(</span><span class="n">fake_output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">cross_entropy</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">fake_output</span><span class="p">),</span> <span class="n">fake_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># WGAN losses</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">critic_loss_fn</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">real_output</span><span class="p">)</span>  <span class="c1"># equation 2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">wgan_generator_loss</span><span class="p">(</span><span class="n">fake_output</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>  <span class="c1"># generator update does not depend on the first term in equation 2</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># Model Builders, simple feedforward networks with 2 hidden layers</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_generator</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">,</span> <span class="n">output_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">latent_dim</span><span class="p">,)),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">output_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_discriminator</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,)),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># using cross entropy from logits, no activation</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># notice how the implementation is the same for discriminator and critic, except critic has added weight clipping</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">build_critic</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">input_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">clip_value</span><span class="o">=</span><span class="mf">0.01</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">const</span> <span class="o">=</span> <span class="n">MaxNorm</span><span class="p">(</span><span class="n">clip_value</span><span class="p">)</span>  <span class="c1"># weight clipping</span>
</span></span><span class="line"><span class="cl">    <span class="n">model</span> <span class="o">=</span> <span class="n">Sequential</span><span class="p">([</span>
</span></span><span class="line"><span class="cl">        <span class="n">Input</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">input_dim</span><span class="p">,)),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_constraint</span><span class="o">=</span><span class="n">const</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">,</span> <span class="n">kernel_constraint</span><span class="o">=</span><span class="n">const</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">        <span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">kernel_constraint</span><span class="o">=</span><span class="n">const</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">model</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># per-iteration/batch training function for both GAN and WGAN</span>
</span></span><span class="line"><span class="cl"><span class="nd">@tf.function</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_gan_step</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">        <span class="n">model</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_train</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">dis_iter</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_size</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">        <span class="n">latent_dim</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
</span></span><span class="line"><span class="cl"><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">dis</span><span class="p">,</span> <span class="n">generator</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;dis&#39;</span><span class="p">],</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;gen&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">dis_loss</span><span class="p">,</span> <span class="n">generator_loss</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;dis_loss&#39;</span><span class="p">],</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;gen_loss&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">dis_opt</span><span class="p">,</span> <span class="n">generator_opt</span> <span class="o">=</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;dis_opt&#39;</span><span class="p">],</span> <span class="n">model</span><span class="p">[</span><span class="s1">&#39;gen_opt&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    <span class="c1"># Loop over discriminator/critic training steps (dis_iter times)</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">dis_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">noise</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="n">batch_idx</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">range</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))[:</span><span class="n">batch_size</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">sample_batch_inner</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">batch_idx</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">disc_tape</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">generated_samples</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">real_output</span> <span class="o">=</span> <span class="n">dis</span><span class="p">(</span><span class="n">sample_batch_inner</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">fake_output_gan</span> <span class="o">=</span> <span class="n">dis</span><span class="p">(</span><span class="n">generated_samples</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">disc_loss</span> <span class="o">=</span> <span class="n">dis_loss</span><span class="p">(</span><span class="n">real_output</span><span class="p">,</span> <span class="n">fake_output_gan</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">gradients_of_discriminator</span> <span class="o">=</span> <span class="n">disc_tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">disc_loss</span><span class="p">,</span> <span class="n">dis</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dis_opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients_of_discriminator</span><span class="p">,</span> <span class="n">dis</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># Train generator</span>
</span></span><span class="line"><span class="cl">    <span class="n">noise</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">latent_dim</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">gen_tape</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">generated_samples</span> <span class="o">=</span> <span class="n">generator</span><span class="p">(</span><span class="n">noise</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">fake_output</span> <span class="o">=</span> <span class="n">dis</span><span class="p">(</span><span class="n">generated_samples</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">gen_loss</span> <span class="o">=</span> <span class="n">generator_loss</span><span class="p">(</span><span class="n">fake_output</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">gradients_of_generator</span> <span class="o">=</span> <span class="n">gen_tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">gen_loss</span><span class="p">,</span> <span class="n">generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">generator_opt</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">gradients_of_generator</span><span class="p">,</span> <span class="n">generator</span><span class="o">.</span><span class="n">trainable_variables</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span>
</span></span></code></pre></div><p>During training, I expected WGANs to be less sensitive to hyperparameter choices than GANs, especially on these simple 2D examples.
However, the weight clipping value $c$ had a significant impact on the learning process.<br>
The original WGAN paper had $c=0.01$, but this made the model update steps way too small, and resulted in converge slower than expected.
Instead, I found that $c=0.5$ worked best. I have included a hyperparameter study pipeline in the notebook for readers to explore.<br>
It seems that having multiple discriminator updates per generator update is also beneficial for GAN training.</p>
<figure id="fig:gaussian" style="text-align: center;">
   <img src="./8gaussian_64_5e-05.gif" alt="d64_lr5e-5" style="display: block; margin: 0 auto;">
   <figcaption style="text-align: left; margin-top: 0.5rem;">Figure 3: Learning on an 8-Gaussian dataset. 
   It is cool how the model is warping the cloud of points into the circular shape.
   </figcaption>
</figure>
<figure id="fig:moon" style="text-align: center;">
   <img src="./moon_128_5e-05.gif" alt="moon" style="display: block; margin: 0 auto;">
   <figcaption style="text-align: left; margin-top: 0.5rem;">Figure 4: Learning on a crescent moon dataset. 
      WGAN is visibly more stable during training
   </figcaption>
</figure>
<figure id="fig:loss" style="text-align: center;">
<div style="display: flex; justify-content: center; gap: 20px;">
   <div>
   <img src="./moon_gan_loss.png" alt="gan_loss" style="display: block; margin: 0 auto;">
   </div>
   <div>
   <img src="./moon_wgan_loss.png" alt="wgan_loss" style="display: block; margin: 0 auto;">
   </div>
</div>
<div style="display: flex; justify-content: center; gap: 20px; margin-top: 0.5rem">
   <div>
   <img src="./moon_gan_grad.png" alt="gan_grad" style="display: block; margin: 0 auto;">
   </div>
   <div>
   <img src="./moon_wgan_grad.png" alt="wgan_grad" style="display: block; margin: 0 auto;">
   </div>
</div>
<figcaption style="text-align: left; margin-top: 0.5rem;">
   Figure 5: Losses and Gradients on the crescent moon dataset. 
   WGAN gradient (bottom right) is much more stable compared to the oscillating GAN gradient (bottom left).
</figcaption>
</figure>
<hr>
<p>Thank you for reading! If you found this post helpful in your own writing or research, please cite it as:</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-bibtex" data-lang="bibtex"><span class="line"><span class="cl"><span class="nc">@article</span><span class="p">{</span><span class="nl">bai2025gan</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">title</span><span class="p">=</span><span class="s">{The Story behind WGAN}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">author</span><span class="p">=</span><span class="s">{Bai, Mark}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">journal</span><span class="p">=</span><span class="s">{rdh1115.github.io}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">year</span><span class="p">=</span><span class="s">{2025}</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">  <span class="na">url</span><span class="p">=</span><span class="s">{https://rdh1115.github.io/posts/literature/gan-wgan/}</span>
</span></span><span class="line"><span class="cl"><span class="p">}</span>
</span></span></code></pre></div>

    </div>

    <footer class="post-footer">
        <ul class="post-tags">
            <li><a href="https://rdh1115.github.io/tags/generative-models/">Generative Models</a></li>
            <li><a href="https://rdh1115.github.io/tags/literature-review/">Literature Review</a></li>
        </ul>

    </footer>
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "https-rdh1115-github-io" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
</article>
    </main>
    
<footer class="footer">
        <span>© 2025 Mark Bai</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
